# Regression and model validation

## To begin with

This week I want to learn how to create colorful plots and print nice-looking tables. Also, I want to learn how to write functions that allow me to extract the necessary numbers from R's output so I can print them in a nice-looking table. All this requires numerous lines of code. To make my report easier to read, I'm leaving some code out of my knitted document. If you want to take a closer look at my work this week, open the chapter2.Rmd file found on GitHub.

## Data

The data in use was collected during the academic year 2014--2015 from the participants of the Introduction to Social Statistics course (Johdatus yhteiskuntatilastotieteeseen). In addition to age (variable age), gender (variable gender), and test scores (variable points), the participants' study skills (variables deep, surf, and stra), and global attitude toward statistic (variable attitude) was asked in a survey. The study skills measures are based on ASSIST (Approaches and Study Skills Inventory for Students) and the measurement of attitudes toward statistics is based on is based on SATS (Survey of Attitudes Toward Statistics). All four variables have been measured with sets of questions, from which a sum of variables has been formed. More information about creating variables can be found at [here](https://www.mv.helsinki.fi/home/kvehkala/JYTmooc/JYTOPKYS2-meta.txt). More information related to the data can be found [here](https://www.mv.helsinki.fi/home/kvehkala/JYTmooc/JYTOPKYS3-meta.txt).

```{r, warning=FALSE, message=FALSE}
#read in the data
learning2014 <- read.csv("C:/Users/Omistaja/Desktop/Opinnot/IODS/IODS-project/data/learning2014.csv")
#structure of the dataset
str(learning2014)
```

There were 183 observations in the original dataset, but to fit the regression model, those observations whose point variable value is zero were removed from the data. This left 166 observations and 7 variables in the dataset.

For the preliminary examination of the variables, I calculated the numbers and percentages for the variable gender and plotted a bar graph to illustrate the proportions of women and men. To describe the sum variables, I chose both a box plot and a histogram to get a better idea of the shapes of the distributions. I described age and points using only histograms. However, since the points are supposed to be the explanatory variable of the regression model, I also plotted the density function on the graph. Also, I calculated some summary statistics describing the distributions to accompany the graphs.

I have saved the tables and graphs in R objects to be able to print them later. In the following code chunks, in the first one, I have calculated some summary statistics, in the second I have printed the summary statistics into tables, and in the third, I have plotted some graphs.

```{r, warning=FALSE, message=FALSE}
# Summary statistics

#libraries
library(psych)
library(psychTools)
library(kableExtra)

#basic statistics:
lrn14_des  <- describe(learning2014[,c(2,7,3:6)], ranges = FALSE,
                       quant = c(0, 0.25, 0.5, 0.75, 1))
lrn14_des <- as.data.frame(lrn14_des)
names(lrn14_des) <- c("vars", "n", "Mean", "SD", "skew", "kurtosis", "SE",
                   "Min.", "1st Qu.", "Median", "3rd Qu.", "Max.")
row.names(lrn14_des) <- c("Age", "Points", "Attitude",
                          "Deep learning", "Strategic learning", "Surface learning")

#Frequencies and percentage of gender
gender_count <- as.data.frame(table(learning2014$gender))
gender_prob <- round(100*prop.table(table(learning2014$gender)), 1)
colnames(gender_count) <- c("gender", "frequency")

gender <- cbind(gender_count$frequency, gender_prob)
gender <- as.data.frame(gender)

colnames(gender) <- c("Frequency", "Percentage (%)")
row.names(gender) <- c("Female", "Male")
```

```{r, warning=FALSE, message=FALSE}
# Tables

k1 <-lrn14_des[, 8:12] %>%
  round(digits=2) %>%
  kable(booktabs=T, align = "c",
        caption = "Some numbers to accompany boxplots") %>% 
  kable_styling(full_width = T)

k2 <- lrn14_des[, 2:7] %>%
  round(digits=2) %>%
  kable(booktabs=T, align = "c",
        caption = "Some numbers to accompany histograms") %>% 
  kable_styling(full_width = T)

k3 <- gender %>%
  kable(booktabs=T, align = "c",
        caption = "Some numbers to accompany the barplot") %>% 
  kable_styling(full_width = F)

```

```{r, warning=FALSE, message=FALSE}
# Plots

library(tidyverse)
library(ggplot2)
library(patchwork)

#Colors for plots
p_cols <- viridis::inferno(36)

# barplot
p1 <- gender_count %>%
  ggplot(aes(x=gender, y=frequency)) +
  geom_bar(stat="identity", color="black", fill=p_cols[c(27, 30)]) +
  ggtitle("Gender", subtitle = "JYT Learning 2014") +
  theme_classic()

# boxplots
p2 <- learning2014[,c(3:6)] %>% pivot_longer(cols = everything()) %>%
  ggplot(aes(y = value, fill=name)) + 
  geom_boxplot(color="black") +
  scale_fill_manual(values=p_cols[3*(4:7)]) +
  scale_x_discrete(labels = NULL, breaks = NULL) + labs(x =" ") +
  ggtitle("Attitudes Toward Statistics & Approaches and Study Skills",
          subtitle = "JYT Learning 2014") +
  theme_classic() +
  facet_wrap(~name, nrow = 1, ncol = 4)

# histograms
p3 <- learning2014[,3:6] %>% pivot_longer(cols = everything()) %>%
  ggplot(aes(x = value, fill=name)) + 
  geom_histogram(binwidth = 1, color="black") +
  scale_fill_manual(values=p_cols[3*(4:7)]) +
  ggtitle("Attitudes Toward Statistics and Approaches and Study Skills",
          subtitle = "JYT Learning 2014") +
  theme_classic() +
  facet_wrap(~name, nrow = 2, ncol = 2)

p4 <- learning2014 %>%
  ggplot(aes(x = age)) + 
  geom_histogram(binwidth = 1, color="black", fill=p_cols[9]) +
  ggtitle("Age", subtitle = "JYT Learning 2014") +
  theme_classic()

p5 <- learning2014 %>%
  ggplot(aes(x = points)) + 
  geom_histogram(aes(y=..density..), binwidth = 1, color="black", fill=p_cols[24]) +
  geom_density(alpha=.5, fill=p_cols[33]) +
  ggtitle("Exam points", subtitle = "JYT Learning 2014") +
  theme_classic()

# additional box plots
p4_2 <- learning2014 %>%
  ggplot(aes(y = age)) + 
  geom_boxplot(color="black", fill=p_cols[9]) +
  scale_x_discrete(labels = "...", breaks = NULL) + labs(x =" ") +
  theme_classic() + coord_flip()

p5_2 <- learning2014 %>%
  ggplot(aes(y = points)) + 
  geom_boxplot(color="black", fill=p_cols[24]) +
  scale_x_discrete(labels = NULL, breaks = NULL) + labs(x =" ") +
  theme_classic( ) + coord_flip()
```

::: row
::: col-md-6
```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height=3, fig.width=3}
p1
```
:::

::: col-md-6
```{r, echo=FALSE, warning=FALSE, message=FALSE}
k3
```
:::
:::

```{r, echo=FALSE, warning=FALSE, message=FALSE}
k1
```

::: row
::: col-md-6
```{r, echo=FALSE, warning=FALSE, message=FALSE}
p2
```
:::

::: col-md-6
```{r, echo=FALSE, warning=FALSE, message=FALSE}
p3
```
:::
:::

```{r, echo=FALSE, warning=FALSE, message=FALSE}
k2
```

::: row
::: col-md-6
```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height=5}
library(patchwork)
p4 + p4_2 + plot_layout(nrow = 2, heights = c(2, 1))
```
:::

::: col-md-6
```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height=5}
library(patchwork)
p5 + p5_2 + plot_layout(nrow = 2, heights = c(2, 1))
```
:::
:::

The age distribution of the students is wide, the youngest student is 17 years old, and the oldest is 55 years old. However, 75% of the students are under 27 years old. Most of the students included in the data are women, in fact, there are 49% fewer men than women.

Looking at the boxplots, it would seem that deep learning was the best learning skill. The lowest possible value of the variable measuring attitude would be (the lowest observed value is 1.4), and the highest possible value, as well as the highest observed value, is 5. For half of the participants, the value of the variable measuring general attitude towards statistics was over 3.2, and for a quarter of the participants over 3.7 .

Exam points are distributed between 7 and 33 so that their mean is 22.72. The distribution of exam point is only slightly skewed and only slightly flat (the skewness is -0.4, and the kurtosis is -0.26). However, the density function drawn on the graph does not resemble a normal distribution, which can be somewhat problematic in terms of fitting the regression model.

Also, there was a nice scatterplot in the Exercise 2, and I want to include it here:

```{r, warning=FALSE, message=FALSE}
library(GGally)
library(ggplot2)

p6 <- ggpairs(learning2014,
              mapping = aes(col = gender, alpha = 0.2),
              lower = list(combo = wrap("facethist", bins = 20)))

for(i in 1:p6$nrow) {
  for(j in 1:p6$ncol){
    p6[i,j] <- p6[i,j] + 
        scale_fill_manual(values=c("orange","steelblue")) +
        scale_color_manual(values=c("orange","steelblue"))  
  }
}

p6 + scale_colour_manual(values=c("orange","steelblue"))+
  ggtitle(" ", subtitle = "JYT Learning 2014") +
  theme_classic()
```

## Fitting a regression model

I was curious to see how well different combinations of variables explain the exam points, and I ended up fitting all kinds of models. I fitted several models with three explanatory variables. I selected a model with the highest multiple R squared and lowest AIC (Akaike information criterion) and BIC (Bayesian information criterion). I used multiple R squared instead of adjusted R squared because I have the same number of explanatory variables in all models. I also checked that I chose a model with statistically significant multiple R squared (F test).

You can find all models from chapter2.Rmd file, just remove 'include=FALSE' from R chunks.

```{r, include=FALSE}
# I am going to create several different models with 3 explanatory variables and then select one of them,
# I am leaving 'gender' out of these models.

# Model variables
model_vars <- c("attitude, deep, stra",
                "attitude, deep, surf",
                "attitude, stra, surf",
                "attitude, deep, age",
                "attitude, stra, age",
                "attitude, surf, age",
                "deep, stra, surf",
                "deep, stra, age",
                "deep, surf, age",
                "stra, surf, age")

# Names for tables
row_names <- c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5",
               "Model 6", "Model 7", "Model 8", "Model 9", "Model 10")
 
```

```{r, include=FALSE}
# Models
model_1 <- lm(points ~ attitude + deep + stra, data = learning2014)
model_2 <- lm(points ~ attitude + deep + surf, data = learning2014)
model_3 <- lm(points ~ attitude + stra + surf, data = learning2014)
model_4 <- lm(points ~ attitude + deep + age, data = learning2014)
model_5 <- lm(points ~ attitude + stra + age, data = learning2014)
model_6 <- lm(points ~ attitude + surf + age, data = learning2014)
model_7 <- lm(points ~ deep + stra + surf, data = learning2014)
model_8 <- lm(points ~ deep + stra + age, data = learning2014)
model_9 <- lm(points ~ deep + surf + age, data = learning2014)
model_10 <- lm(points ~ stra + surf + age,  data = learning2014)
```

```{r, include=FALSE}
#define function to coefficients of model
coefficients <- function(x) {
    coeff <- as.data.frame(summary(x)$coefficients)
    return(coeff)
}

#define function to R squared of model
r_squared <- function(x) {
    f <- summary(x)$r.squared
    attributes(f) <- NULL
    return(f)
}

#define function to adjusted R squared score of model
adj_r_squared <- function(x) {
    f <- summary(x)$adj.r.squared
    attributes(f) <- NULL
    return(f)
}

#define function to F test statisic of model
F_test_stat <- function(x) {
    f <- summary(x)$fstatistic
    f_test <- f[1]
    attributes(f_test) <- NULL
    return(f_test)
}

#define function to F test df of model
F_test_df <- function(x) {
    f <- summary(x)$fstatistic
    f_test <- f[2:3]
    attributes(f_test) <- NULL
    return(f_test)
}

#define function to extract overall p-value of model
overall_p <- function(x) {
    f <- summary(x)$fstatistic
    p <- pf(f[1],f[2],f[3],lower.tail=F)
    attributes(p) <- NULL
    return(p)
}
```

```{r, include=FALSE}
# F test

#extract R squared of model
r_sqrd <- c(r_squared(model_1), r_squared(model_2), r_squared(model_3), r_squared(model_4),
            r_squared(model_5), r_squared(model_6), r_squared(model_7), r_squared(model_8),
            r_squared(model_9), r_squared(model_10))

#extract F test statistic of model
F_t_s <- c(F_test_stat(model_1), F_test_stat(model_2), F_test_stat(model_3), F_test_stat(model_4),
            F_test_stat(model_5), F_test_stat(model_6), F_test_stat(model_7), F_test_stat(model_8),
            F_test_stat(model_9), F_test_stat(model_10))

#extract F test df of model
F_t_df <- rbind(F_test_df(model_1), F_test_df(model_2), F_test_df(model_3), F_test_df(model_4),
            F_test_df(model_5), F_test_df(model_6), F_test_df(model_7), F_test_df(model_8),
            F_test_df(model_9), F_test_df(model_10))

#extract overall p-value of model
p_values <- c(overall_p(model_1), overall_p(model_2), overall_p(model_3), overall_p(model_4),
              overall_p(model_5), overall_p(model_6), overall_p(model_7), overall_p(model_8),
              overall_p(model_9), overall_p(model_10))

F_test <- as.data.frame(cbind(model_vars, 100*round(r_sqrd, 4),
                              round(F_t_s, 3), paste(F_t_df[,1],F_t_df[,2] ,sep=","),
                              round(p_values, 3)))

rownames(F_test) <- row_names
colnames(F_test) <- c("Variables", "Multiple R-squared (%)", "F test statisic",
                               "df", "p-value")
k5 <- F_test %>%
  kable(booktabs=T, align = "lcccc",
        caption = "F test") %>% 
  kable_styling(full_width = T)
k5
```

```{r, include=FALSE}
# fit indices

#extract adjusted R squared of model
adj_r_sqrd <- c(adj_r_squared(model_1), adj_r_squared(model_2), adj_r_squared(model_3),
                adj_r_squared(model_4), adj_r_squared(model_5), adj_r_squared(model_6),
                adj_r_squared(model_7), adj_r_squared(model_8), adj_r_squared(model_9),
                adj_r_squared(model_10))

# BIC
bics <- c(BIC(model_1), BIC(model_2), BIC(model_3), BIC(model_4),
          BIC(model_5), BIC(model_6), BIC(model_7), BIC(model_8),
          BIC(model_9), BIC(model_10))

# AIC
aics <- c(AIC(model_1), AIC(model_2), AIC(model_3), AIC(model_4),
          AIC(model_5), AIC(model_6), AIC(model_7), AIC(model_8),
          AIC(model_9), AIC(model_10))

fit_indices <- as.data.frame(cbind(model_vars, 100*round(adj_r_sqrd, 4),
                                  round(aics, 0),round(bics, 0)))
rownames(fit_indices) <- row_names
colnames(fit_indices) <- c("Variables", "Adjusted R-squared (%)",
                               "AIC", "BIC")
k6 <- fit_indices %>%
  kable(booktabs=T, align = "lcccc",
        caption = "Fit Indices") %>% 
  kable_styling(full_width = T)
k6
```

```{r, include=FALSE}
col_names <- c(" ", "Estimate", "Std. Error", "t value", "p-value")

#define function to F test df of model
coefficients <- function(x) {
    coeff <- as.data.frame(summary(x)$coefficients)
#    attributes(coeff) <- NULL
    return(coeff)
}

models0 <- rbind(coefficients(model_1), coefficients(model_2), coefficients(model_3),
                             coefficients(model_4), coefficients(model_5), coefficients(model_6),
                             coefficients(model_7),coefficients(model_8),coefficients(model_9),
                             coefficients(model_10))

row_names2 <- c("Intercept", "attitude", "deep", "stra",
                "Intercept", "attitude", "deep", "surf",
                "Intercept", "attitude", "stra", "surf",
                "Intercept", "attitude", "deep", "age",
                "Intercept", "attitude", "stra", "age",
                "Intercept", "attitude", "surf", "age",
                "Intercept", "deep", "stra", "surf",
                "Intercept", "deep", "stra", "age",
                "Intercept", "deep", "surf", "age",
                "Intercept", "stra", "surf", "age")

models <- as.data.frame(cbind(row_names2, round(models0, 3)))
colnames(models) <- col_names

k7 <- models %>%
kable(row.names = FALSE, booktabs=T, align = c("l","c","c","c","c"),
      caption = "Model parameters for models 1-10") %>%
  pack_rows("Model 1", 1,4) %>%
  pack_rows("Model 2", 5,8) %>%
  pack_rows("Model 3", 9,12) %>%
  pack_rows("Model 4", 13,16) %>%
  pack_rows("Model 5", 17,20) %>%
  pack_rows("Model 6", 21,24) %>%
  pack_rows("Model 7", 25,28) %>%
  pack_rows("Model 8", 29,32) %>%
  pack_rows("Model 9", 33,36) %>%
  pack_rows("Model 10", 37,40) %>%
add_header_above(c("Model parameters" = 5)) %>%
kable_styling(full_width = T)
k7
```

```{r, warning=FALSE, message=FALSE}
# Scatter plots

p7 <- qplot(attitude, points, data = learning2014) + 
  geom_smooth(method = "lm", col="steelblue") + 
  ggtitle("Points and ", subtitle = "JYT Learning 2014") +
  theme_classic()


p8 <- qplot(stra, points, data = learning2014) + 
  geom_smooth(method = "lm", col="#C70039") + 
  ggtitle("Points and strategic learning", subtitle = "JYT Learning 2014") +
  theme_classic()

p9 <- qplot(age, points, data = learning2014) + 
  geom_smooth(method = "lm", col="#228B22") + 
  ggtitle("Points and age", subtitle = "JYT Learning 2014") +
  theme_classic()

library(patchwork)
 p7 + p8 + p9 + plot_layout(nrow = 2)
```

I fitted three models, the first with three explanatory variables, the second with two, and the third with only one. Each time I removed one variable with the highest p-value of the regression coefficient from the model.

```{r}
# selected models
my_model_1 <- lm(points ~ attitude + stra + age, data = learning2014)
#summary(my_model_1)
my_model_2 <- lm(points ~ attitude + stra, data = learning2014)
#summary(my_model_2)
my_model_3 <- lm(points ~ attitude, data = learning2014)
#summary(my_model_3)
```

I googled for code to extract p-values from model summaries. I edited the function I found in such a way I could extract the other information I wanted from the model summaries. You can find the original code [here](https://www.statology.org/r-extract-p-value-from-lm/).

```{r, message=FALSE, warning=FALSE}
#define function to coefficients of model
coefficients <- function(x) {
    coeff <- as.data.frame(summary(x)$coefficients)
    return(coeff)
}

#define function to R squared of model
r_squared <- function(x) {
    f <- summary(x)$r.squared
    attributes(f) <- NULL
    return(f)
}

#define function to adjusted R squared score of model
adj_r_squared <- function(x) {
    f <- summary(x)$adj.r.squared
    attributes(f) <- NULL
    return(f)
}

#define function to F test statisic of model
F_test_stat <- function(x) {
    f <- summary(x)$fstatistic
    f_test <- f[1]
    attributes(f_test) <- NULL
    return(f_test)
}

#define function to F test df of model
F_test_df <- function(x) {
    f <- summary(x)$fstatistic
    f_test <- f[2:3]
    attributes(f_test) <- NULL
    return(f_test)
}

#define function to extract overall p-value of model
overall_p <- function(x) {
    f <- summary(x)$fstatistic
    p <- pf(f[1],f[2],f[3],lower.tail=F)
    attributes(p) <- NULL
    return(p)
}
```

After that, I extracted the information I wanted into three different tables as follows: the first table contains the regression coefficients and the the related t-tests, the second table shows the multiple R-squareds and related statistical tests. The third table shows the adjusted R-squareds as well as AIC and BIC.

```{r, message=FALSE, warning=FALSE}
# First table
col_names <- c(" ", "Estimate", "Std. Error", "t value", "p-value")

models0 <- rbind(coefficients(my_model_1), coefficients(my_model_2), coefficients(my_model_3))

row_names3 <- c("Intercept", "attitude", "stra", "age",
                "Intercept", "attitude", "stra",
                "Intercept", "attitude")

models <- as.data.frame(cbind(row_names3, round(models0, 3)))
colnames(models) <- col_names

k8 <- models %>%
kable(row.names = FALSE, booktabs=T, align = c("l","c","c","c","c"),
      caption = "Model parameters") %>%
  pack_rows("Model 1", 1,4) %>%
  pack_rows("Model 2", 5,7) %>%
  pack_rows("Model 3", 8,9) %>%
add_header_above(c("Model parameters" = 5)) %>%
kable_styling(full_width = T)
```

```{r, message=FALSE, warning=FALSE}
# Second table
# F test

#extract R squared of model
r_sqrd_3 <- c(r_squared(my_model_1), r_squared(my_model_2), r_squared(my_model_3))

#extract F test statistic of model
F_t_s_3 <- c(F_test_stat(my_model_1), F_test_stat(my_model_2), F_test_stat(my_model_3))

#extract F test df of model
F_t_df_3 <- rbind(F_test_df(my_model_1), F_test_df(my_model_2), F_test_df(my_model_3))

#extract overall p-value of model
p_values_3 <- c(overall_p(my_model_1), overall_p(my_model_2), overall_p(my_model_3))

F_test_3 <- as.data.frame(cbind(100*round(r_sqrd_3, 4),
                              round(F_t_s_3, 3), paste(F_t_df_3[,1],F_t_df_3[,2] ,sep=","),
                              round(p_values_3, 3)))

colnames(F_test_3) <- c("Multiple R-squared (%)", "F test statisic",
                               "df", "p-value")

rownames(F_test_3) <- c("Model 1", "Model 2", "Model 3")

k9 <- F_test_3 %>%
  kable(booktabs=T, align = "cccc",
        caption = "F test") %>% 
  kable_styling(full_width = T)
```

```{r, message=FALSE, warning=FALSE}
# Third table
# fit indices

#extract adjusted R squared of model
adj_r_sqrd_3 <- c(adj_r_squared(my_model_1), adj_r_squared(my_model_2), adj_r_squared(my_model_3))

# BIC
bics_3 <- c(BIC(my_model_1), BIC(my_model_2), BIC(my_model_3))

# AIC
aics_3 <- c(AIC(my_model_1), AIC(my_model_2), AIC(my_model_3))

fit_indices_3 <- as.data.frame(cbind(100*round(adj_r_sqrd_3, 4),
                                  round(aics_3, 0),round(bics_3, 0)))

colnames(fit_indices_3) <- c("Adjusted R-squared (%)",
                               "AIC", "BIC")
rownames(fit_indices_3) <- c("Model 1", "Model 2", "Model 3")

k10 <- fit_indices_3 %>%
  kable(booktabs=T, align = "cccc",
        caption = "Fit Indices") %>% 
  kable_styling(full_width = T)
```

```{r, message=FALSE, warning=FALSE}
k8
```

My first model had three explanatory variables, but the regression coefficients for two of them were not statistically significant. I removed the variable age from the model because it has the highest p-value of the regression coefficient. Now the remaining model has attitude and strategic learning as variables, but still, the regression coefficient of the variable strategic learning does not deviate from zero statistically significantly. For this reason, I removed the variable strategic learning from the model, so that only attitude remained in my final model.

```{r, message=FALSE, warning=FALSE}
k9
```

The multiple R squared of all three models deviates from zero statistically significantly. Since model 1 has the most variables, it is understandable that its explanatory power is the greatest, even when we look at the adjusted R squared.
I also tried model selection using adjusted R squared., AIC, and BIC. However, I got puzzled because this time BIC increases while AIC decreases. I can only hope this is not due to a bug in the code.

```{r, message=FALSE, warning=FALSE}
k10
```

In the model I chose, there is only one explanatory variable left, the global attitude toward statistics. The regression coefficient of the variable is about 3.5, indicating that when the global attitude toward statistics increases by one unit, the exam points increase by about 3.5 points. The R squared of the model is about 0.19, so based on the model, it can be concluded that the global attitude toward statistics explains about 19% of the variation in test scores.

## Graphical model validation

The explanatory variable and the target variable are at least interval-scaled, and the variance of the explanatory variable is not zero. Since there is only one explanatory variable, multicollinearity is not a problem.

The basic assumption of the linear model is a linear relationship between the variable y and the explanatory variables under consideration. The correlation between scores and attitude is 0.437, and by looking at the scatterplot, the relationship seems linear. A possible non-linear connection could also be observed in a scatterplot with residual terms and an explanatory variable.

```{r, message=FALSE, warning=FALSE, fig.height=6, fig.width=5.5}
# normal q-q plot
plot(my_model_3, 2)
```

The classical linear model assumes a normal distribution. The better the normal distribution assumption is valid, the better the points of the normal q-q plot are on the diagonal straight line piercing the graph. The plot shows the standardized residual terms between the quantiles and the standard normal distribution between the quantiles. On both sides of the graph, the points are slightly below the diagonal. This suggests that the distribution of the residuals is more peaked than the normal distribution. In addition, the graph looks a bit like the distribution is skewed to the left.

```{r, message=FALSE, warning=FALSE, fig.height=6, fig.width=7}
# residuals vs fitted
plot(my_model_3, 1)
```

When the residual terms and the fitted values are plotted on the same graph, the graph should look like sand has been thrown on paper. The distribution of residual terms should be random and lie evenly on both sides of zero. The outliers in the data pull the graph in a slightly negative direction. However, the regression smoothing drawn in the figure does not deviate greatly from the straight line. However, with large fitting values, it rises slightly, indicating a slight bias in the data.

```{r, message=FALSE, warning=FALSE, fig.height=6, fig.width=7}
# residual vs leverage
plot(my_model_3, 5)
```

The leverage tells which observations have the most influence on the model. The fit of the model could be improved by removing the observations with the most leverage from the data. However, in this model, the leverage of the observations is reasonably small, and even the observations with the largest Cook's distance (35, 56, and 71) do not have large leverage.

\-\-\-\-\-\-\-\-\-\--

*This document was last knitted on*

```{r, echo=FALSE}
date()
```
